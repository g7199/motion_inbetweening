import argparse
import os
os.environ['PYGAME_HIDE_SUPPORT_PROMPT'] = "1"
import pygame
from OpenGL.GL import *
from OpenGL.GLU import *
import numpy as np
import imageio
from pyglm import glm
import sys
import math
import torch

# --- ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ ì„í¬íŠ¸ (ê¸°ì¡´ ì½”ë“œ ê°€ì •) ---
from bvh_tools.Rendering import draw_humanoid, draw_trajectory
from bvh_tools.utils import draw_axes, set_lights
from bvh_tools.bvh_controller import parse_bvh, get_preorder_joint_list  # BVH íŒŒì‹± ëª¨ë“ˆ
from bvh_tools.virtual_transforms import extract_xz_plane  # virtual root axisìš©
from bvh_tools.Rendering import draw_virtual_root_axis  # ê°€ì • (ë·°ì–´ì— ìˆìŒ)
from bvh_tools.utils import random_color  # ìƒ‰ìƒ ëœë¤

# ----------------- ì„¤ì • -----------------
WINDOW_WIDTH, WINDOW_HEIGHT = 1280, 720
# ----------------------------------------

def create_fbo(width, height):
    """ FBOì™€ í…ìŠ¤ì²˜, ëìŠ¤ ë²„í¼ë¥¼ ìƒì„±í•˜ê³  IDë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. """
    fbo = glGenFramebuffers(1)
    glBindFramebuffer(GL_FRAMEBUFFER, fbo)

    texture = glGenTextures(1)
    glBindTexture(GL_TEXTURE_2D, texture)
    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, width, height, 0, GL_RGB, GL_UNSIGNED_BYTE, None)
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)
    glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, texture, 0)

    rbo = glGenRenderbuffers(1)
    glBindRenderbuffer(GL_RENDERBUFFER, rbo)
    glRenderbufferStorage(GL_RENDERBUFFER, GL_DEPTH_COMPONENT24, width, height)
    glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, rbo)

    if glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE:
        print("FBO ìƒì„± ì‹¤íŒ¨!", file=sys.stderr)
        return None, None, None

    glBindFramebuffer(GL_FRAMEBUFFER, 0)
    return fbo, texture, rbo

def save_video(frames, filename, fps):
    """ NumPy ë°°ì—´ë¡œ ëœ í”„ë ˆì„ ëª©ë¡ì„ ë™ì˜ìƒ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. """
    print(f"\në™ì˜ìƒì„ ì €ì¥í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... ì´ {len(frames)} í”„ë ˆì„")
    with imageio.get_writer(filename, fps=fps, quality=8) as writer:
        for frame in frames:
            writer.append_data(frame)
    print(f"ğŸ¥ ë™ì˜ìƒì´ {filename} ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

def encode(bvh_paths, output_filename="rendering/output.mp4", trajectory=None, start_frame=0, clip_length=None):
    """
    BVH íŒŒì¼(ë“¤)ì„ ì½ì–´ì„œ ë Œë”ë§í•˜ê³  MP4ë¡œ ì €ì¥.
    - bvh_paths: list of str (BVH íŒŒì¼ ê²½ë¡œë“¤).
    - trajectory: optional, draw_trajectoryìš© ë°ì´í„° (e.g., ë¡œë“œëœ ë°ì´í„°).
    - start_frame: ë Œë”ë§ ì‹œì‘ í”„ë ˆì„ (default: 0).
    - clip_length: ë Œë”ë§í•  í”„ë ˆì„ ê¸¸ì´ (default: None, Noneì´ë©´ ì „ì²´ í”„ë ˆì„ ì‚¬ìš©).
    """
    motions = []
    max_frames = 0
    for file_path in bvh_paths:
        if not os.path.exists(file_path):
            print(f"Warning: BVH íŒŒì¼ '{file_path}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
            continue
        
        root, motion = parse_bvh(file_path)
        joint_order = get_preorder_joint_list(root)
        motion.build_quaternion_frames(joint_order)
        virtual_root = motion.apply_virtual(root)  # virtual root ì ìš©
        
        entry = {
            'name': os.path.basename(file_path),
            'root': virtual_root,
            'motion': motion,
            'frame_len': motion.frames,
            'color': random_color()  # ë·°ì–´ì²˜ëŸ¼ ëœë¤ ìƒ‰ìƒ
        }
        motions.append(entry)
        
        if motion.frames > max_frames:
            max_frames = motion.frames  # ê°€ì¥ ê¸´ ëª¨ì…˜ì— ë§ì¶¤
    
    if not motions:
        print("Error: ìœ íš¨í•œ BVH íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # FPS ê³„ì‚°: ì²« ë²ˆì§¸ motionì˜ frame_time ì‚¬ìš© (BVH í‘œì¤€)
    fps = 1.0 / motions[0]['motion'].frame_time if hasattr(motions[0]['motion'], 'frame_time') else 60.0
    print(f"ë Œë”ë§ FPS: {fps:.2f}")

    # ë£¨í”„ ë²”ìœ„ ë™ì  ì„¤ì • (ìƒˆë¡œ ì¶”ê°€: clip_length ì§€ì • ì‹œ ë²”ìœ„ ì œí•œ, ì•„ë‹ˆë©´ ì „ì²´)
    if clip_length is not None:
        total_frames = clip_length
        frame_range = range(start_frame, start_frame + clip_length)
        if start_frame + clip_length > max_frames:
            print(f"Warning: Requested range ({start_frame} to {start_frame + clip_length - 1}) exceeds max_frames ({max_frames}). Clipping to available frames.")
            frame_range = range(start_frame, min(start_frame + clip_length, max_frames))
    else:
        total_frames = max_frames
        frame_range = range(total_frames)  # default: 0 to max_frames - 1
    
    print(f"Rendering frames: {frame_range.start} to {frame_range.stop - 1} (total: {len(frame_range)})")

    # 2. Pygame ë° OpenGL ì´ˆê¸°í™” (í™”ë©´ ì—†ëŠ” ëª¨ë“œ)
    pygame.init()
    size = (WINDOW_WIDTH, WINDOW_HEIGHT)
    pygame.display.set_mode(size, pygame.DOUBLEBUF | pygame.OPENGL | pygame.HIDDEN)

    # 3. FBO ìƒì„±
    fbo, texture, rbo = create_fbo(*size)
    if fbo is None:
        pygame.quit()
        return None

    # 4. ë Œë”ë§ í™˜ê²½ ë° ì¹´ë©”ë¼ ì„¤ì • (ë·°ì–´ state ì°¸ê³ )
    glEnable(GL_DEPTH_TEST)
    set_lights()
    camera_eye = glm.vec3(60, 180, 600)  # ë·°ì–´ ì´ˆê¸°ê°’
    camera_center = glm.vec3(0, 80, 0)
    camera_up = glm.vec3(0, 1, 0)

    # 5. í”„ë ˆì„ë³„ ë Œë”ë§ ë£¨í”„ (í•˜ë“œì½”ë”© ëŒ€ì‹  ë™ì  frame_range ì‚¬ìš©)
    recorded_frames = []
    first_kin = None
    for idx, frame_idx in enumerate(frame_range):  # enumerateë¡œ ì§„í–‰ë¥  ê³„ì‚°ìš© idx
        glBindFramebuffer(GL_FRAMEBUFFER, fbo)
        
        glViewport(0, 0, *size)
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)
        glMatrixMode(GL_PROJECTION)
        glLoadIdentity()
        gluPerspective(45.0, size[0] / size[1], 0.1, 5000.0)
        glMatrixMode(GL_MODELVIEW)
        glLoadIdentity()

        gluLookAt(camera_eye.x, camera_eye.y, camera_eye.z,
                  camera_center.x, camera_center.y, camera_center.z,
                  camera_up.x, camera_up.y, camera_up.z)
        draw_axes()
        
        if trajectory is not None:
            draw_trajectory(trajectory)  # optional
        
        # ê° ëª¨ì…˜ ë Œë”ë§ (ë·°ì–´ì²˜ëŸ¼ motions ë£¨í”„)
        for motion_entry in motions:
            # í”„ë ˆì„ ì ìš© (frame_idxë¥¼ ì‚¬ìš©: BVHì˜ ì‹¤ì œ ì¸ë±ìŠ¤)
            local_idx = frame_idx % motion_entry['frame_len']
            motion_entry['motion'].apply_to_skeleton(local_idx, motion_entry['root'])

            # ì „ì²´ kinematics í–‰ë ¬ ê°€ì ¸ì˜¤ê¸°
            global_kinematics = np.array(motion_entry['root'].kinematics)

            if first_kin is None:
                first_kin = global_kinematics.copy()
                motion_entry['root'].kinematics = glm.mat4(1.0)
            else:
                # ì²« ë²ˆì§¸ í”„ë ˆì„ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€í™”
                first_inv = np.linalg.inv(first_kin)
                relative_kinematics = first_inv @ global_kinematics
            
                # GLMìœ¼ë¡œ ì ìš©
                motion_entry['root'].kinematics = glm.mat4(*relative_kinematics.T.flatten())

            # íœ´ë¨¸ë…¸ì´ë“œ ê·¸ë¦¬ê¸°
            draw_humanoid(motion_entry['root'], motion_entry['color'])
            
            # virtual root axis ê·¸ë¦¬ê¸° (ë·°ì–´ ëŠë‚Œ ë°˜ì˜)
            if motion_entry['root'].children:
                combined_kin = motion_entry['root'].kinematics * motion_entry['root'].children[0].kinematics
                draw_virtual_root_axis(combined_kin, motion_entry['color'])

        # í”„ë ˆì„ ìº¡ì²˜
        glReadBuffer(GL_COLOR_ATTACHMENT0)
        pixels = glReadPixels(0, 0, *size, GL_RGB, GL_UNSIGNED_BYTE)
        image = np.frombuffer(pixels, dtype=np.uint8).reshape(size[1], size[0], 3)
        image = np.flipud(image)
        recorded_frames.append(image)

        glBindFramebuffer(GL_FRAMEBUFFER, 0)
        
        # ì§„í–‰ë¥  ì¶œë ¥ (idxë¡œ 1ë¶€í„° ì‹œì‘)
        print(f"\rë Œë”ë§ ì§„í–‰ë¥ : {idx + 1} / {len(frame_range)} (frame {frame_idx})", end="")

    # 6. ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ë° ë™ì˜ìƒ ì €ì¥
    glDeleteRenderbuffers(1, [rbo])
    glDeleteTextures(1, [texture])
    glDeleteFramebuffers(1, [fbo])
    
    save_video(recorded_frames, output_filename, fps)
    pygame.quit()
    
    return output_filename

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="BVH íŒŒì¼ì„ ë Œë”ë§í•˜ì—¬ MP4 ë¹„ë””ì˜¤ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    parser.add_argument('--path', nargs='+', required=True, help="BVH íŒŒì¼ ê²½ë¡œ(ë“¤). ì—¬ëŸ¬ ê°œ ì§€ì • ê°€ëŠ¥.")
    parser.add_argument('--output', default="rendering/output.mp4", help="ì¶œë ¥ MP4 íŒŒì¼ëª… (default: rendering/output.mp4)")
    parser.add_argument('--trajectory', default=None, help="Trajectory ë°ì´í„° íŒŒì¼ ê²½ë¡œ (optional)")
    parser.add_argument('--start_frame', type=int, default=0, help="ë Œë”ë§ ì‹œì‘ í”„ë ˆì„ (default: 0)")
    parser.add_argument('--clip_length', type=int, default=None, help="ë Œë”ë§í•  í”„ë ˆì„ ê¸¸ì´ (default: None, ì „ì²´ í”„ë ˆì„ ì‚¬ìš©)")

    args = parser.parse_args()

    # trajectory ë¡œë“œ (í•„ìš” ì‹œ êµ¬í˜„. ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ strë¡œ ì „ë‹¬)
    trajectory_data = None
    if args.trajectory:
        # ì˜ˆ: trajectory íŒŒì¼ ë¡œë“œ (ì‹¤ì œ êµ¬í˜„ í•„ìš”, e.g., np.load(args.trajectory))
        print(f"Trajectory ë¡œë”©: {args.trajectory}")
        trajectory_data = torch.load(args.trajectory)  # placeholder: ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì½”ë“œ ì¶”ê°€
        

    encode(args.path, args.output, trajectory=trajectory_data, start_frame=args.start_frame, clip_length=args.clip_length)